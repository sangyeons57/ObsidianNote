소프트 맥스 회귀는 다중 클레스 분류문제를 해결하기 위해 설계된 알고리즘이다.

예를들어 사진을 받아 이 사진이 강아지인지, 고양이 인지, 소인지 판단해야할때 사용하는 알고리즘이다.

스프트 맥스 회귀는
만약에 3개의 선택지 가있을떄
1 0 0 / 0 1 0 / 0 0 1 처럼 선택지의 확률을 전부 합했을떄 1이 되어야하고 
정답을 표시한떄는 위처럼 선택된 값만 1이 된다.

소프트 맥스는 
$$
softmax(z)_i = \frac{e^{z_i}}{\sum_{j=1}^{3} e^{z_j}}
$$
위 식처럼
$$
e^{l_1} + e^{l_2} + e^{l_3}
$$
이런 형태로전체값을 구하고

$$
e^{l_1}
$$
로 그중 한가지 값을 구해서

해당 1번쨰 값이 전체의 얼만큼을 차지하는지 측정한다.


소프트 맥스 회귀가 모델의 예측에 사용된다면
아레 크로스 엔트로피는 정확도를 평가하는 데 사용한다.
$$
L = -\sum_{i=1}^{N} y_i \log(\hat{y}_i)
$$
이식이만들어지는 과정은 [[로지스틱 회귀와 우도(likelihood)]] 와 비슷 한데

$$
q^{y_1} q^{y_2} q^{y_3}
$$
이런식으로 예측값을 구할수있다
이떄 y1, y2, y3에 들어가는 것은 위에 나오는 1, 0, 0 같은 정답값을 의미한다
그러면 정답이 되는값만 나와서 likelihood처럼 로스를 구할수 있게 된다.

그리고 여기에  -log를 취하게 되면
곱 형태로 이루어진 식이 로그의 곱셈법칙에 따라 합형태를 띄게 된다.  이떄 log를 취할수 있는 이유는  위에 링크된것 처럼 단조 증가 함수 이기 때문이다.

또한 원 핫 인코딩(1,0,0 처럼 옳은것을 표시 하는 방식) 이기 때문에 한쪽에 오차만 줄이면 나머지 오차는 자동으로 줄어 들기때문에 오차 는 정답에 해당하는 쪽에만 적용해 주는 것 처럼 된다.


소프트 멕스가 로스값을 구하는 도구로 사용해서
크로스 엔트로피에 q값에 소프트 멕스가 적용된 값을 넣어서 신경망에서 소프트 맥스를 분리하는 경우가 많기도 하다.


결국 인공지능은
1. 입, 출력을 정의하고
2. 모델을 만들고
3. 로스를 정의하고
4. wights 를 최적화
허눈 과정을 거친다.


시그모이드에 비해 소프트 맥스의 다중분류에서 장점은
1. Saturation문제가 없다
2. 상대 평가가 가능하다.
3. exponentional fuction(e^x 자연상수 함수)을 사용해서 더욱 두드러진게 표현 할수 있다.

