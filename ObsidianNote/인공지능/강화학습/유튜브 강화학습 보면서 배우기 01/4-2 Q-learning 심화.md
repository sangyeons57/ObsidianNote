[유튜브](https://youtu.be/k0VoyCZjbMY?si=1YITsY12m0_LYrIC)
Q-learning에서 
Target Policy는 Greedy이다.
Behavior Policy는 e-Greedy 이다.

Q-러닝은 모델 없이 학습하는 강화 학습 기법 가운데 하나입니다. 주어진 유한 마르코프 결정 과정의 최적의 정책을 찾기 위해 사용할 수 있습니다. Q-러닝은 특정 상태에서의 행동의 가치를 학습하는 모델-프리 강화학습 알고리즘입니다. 이는 환경의 모델이 필요하지 않으며, 확률적인 전환과 보상을 처리할 수 있습니다. 무한 탐색 시간과 부분적으로 무작위 정책이 주어진 경우, 어떤 마르코프 결정 과정에 대한 최적의 정책을 식별할 수 있습니다.

Q-러닝 알고리즘의 구체적인 작동 방식은 다음과 같습니다:

알고리즘 파라미터 셋팅: step, size, α (Learning Rate), ϵ (Explorer)
Q값 초기화: Q (종료, *) = 0, 나머지는 임의의 값
반복 – 에피소드 (게임)가 종료되면 다시 실행
상태 초기화
반복 – Step (에피소드가 종료될 때까지)
행동 A 선택 (ϵ (탐험):랜덤 or greedy (탐욕적): optimal policy)
환경으로부터 행동 A 했을 때의 R, S’ 값 얻음
Q값 업데이트
상태이동: S<-S’
여기서, greedy-policy (탐욕적 정책)는 action (행동)을 취하는 정책 (policy)이 Q가 최대 (max)일 때의 행동이므로 학습된 Q만 따라가면서 행동합니다. 그렇기 때문에 때로는 무작위 (random)로 행동을 취해야 합니다. 이를 explorer (탐험)이라고 합니다.