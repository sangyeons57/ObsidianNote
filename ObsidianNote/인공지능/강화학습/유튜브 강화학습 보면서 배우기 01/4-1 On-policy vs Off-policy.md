[유튜브](https://youtu.be/wVhH_3Td_R4?si=zRoS3G9ZpuFxRzYU)
TD에 유명한게 SARASA 와 Q-learning이 있다

이중 SARSA 는 On-policy에 포함되고
Q-learning은 Off-policy이다.

On-Policy는 Behvior policy == TargetPolicy
Off -policy는 Behvior policy != TargetPolicy

Behvior Policy = 실제 행동 (지금해동)
Target Policy = TD Traget 셈플 (TD Target을 만들기위한 값)

On-Policy는 같은 행동을 하고 개선을함 이전까지 하던방식
- **정책 평가와 개선이 동시에 이루어짐:** On-policy 학습에서는 에이전트가 현재 정책을 사용하여 행동하면서 동시에 그 정책을 평가하고 개선합니다. 즉, 에이전트는 수집한 데이터를 기반으로 정책을 업데이트합니다.
- **샘플 효율성이 낮을 수 있음:** 에이전트가 학습을 위해 직접 수집한 데이터를 사용하기 때문에 효율성이 낮을 수 있습니다.
**On-policy:** 에이전트는 현재 정책에 따라 행동을 선택하고, 그 결과를 사용하여 정책을 업데이트합니다.

Off_policy 는 
- **데이터 재사용:** Off-policy 학습에서는 에이전트가 이전에 수집한 데이터를 재사용하여 학습합니다. 에이전트는 현재 정책과는 독립적으로 이전에 경험한 데이터를 사용하여 학습합니다.
- **샘플 효율성이 높을 수 있음:** 이전에 수집한 데이터를 재사용하므로 학습 효율성이 향상될 수 있습니다.
- **중요도 샘플링 등의 기술 사용:** Off-policy 학습에서는 데이터의 중요도를 고려하는 기술들이 사용될 수 있습니다. 예를 들면 중요도 샘플링(Importance Sampling) 등이 있습니다.
**Off-policy:** 에이전트는 이전에 수집한 경험 데이터에서 행동을 선택하고, 선택한 행동에 대한 결과를 사용하여 정책을 업데이트합니다.

Off - Policy를  사용하는이유
1. 사람 또는 다른 AI의 값을 사용할수있다.
2. 실컷 탐험하면서 최적 셈플도 얻을수있다.
3. 재평가(재판단) 할수있다.

1.  판단과 행동을 따로 할수있다. 다른 예시를 들수있다. 그러니까 자기행동으로 한번 계산하고 남으 행동으로 한번더 계산하고 
2. Target Policy는 Greedy하게 하지만 Target Policy(실제행동) 은 e-Greedy함으로 다양하게 실험할수있다.
3. 과거에 해당 상태에서 했던 행동을 현재에 다시해서 현재 다시 리워드를 받아보는거다. 하지만 리워드를 받기만 하고 실제로 행동하지는않는다.








On policy와 off policy는 강화학습에서 다른 정책을 학습하고 평가하는 방식을 말합니다. On policy는 현재 정책을 따라 행동하면서 그 정책을 개선하는 방식이고, off policy는 현재 정책과 다른 정책을 학습하는 방식입니다.

On policy의 장점은 구현이 쉽고 여러 종류의 정책에 적용 가능하다는 것입니다. 단점은 데이터 효율성이 떨어지고 탐험과 활용의 균형을 잘 맞춰야 한다는 것입니다. On policy의 예로는 SARSA, A2C, A3C, PPO 등이 있습니다.

Off policy의 장점은 다른 사람이나 에이전트의 행동을 관찰하거나 이전의 정책으로 생성된 데이터를 재사용할 수 있다는 것입니다. 또한 탐험적인 정책을 따르면서도 최적의 정책을 학습할 수 있고, 여러 정책을 동시에 학습할 수도 있습니다. 단점은 중요도 샘플링이나 함수 근사화 등의 기법이 필요하고, 분산이 커질 수 있다는 것입니다. Off policy의 예로는 Q-learning, DQN, DDPG, TD3, SAC 등이 있습니다

재사용이란
Q-learning은 현재 정책에서 선택한 행동 a와는 상관없이 Q(s,a)를 업데이트할 때 다음 상태 s’에서 가장 큰 Q값을 가지는 행동 a’를 사용합니다. 즉, Q-learning은 현재 정책과 다른 정책을 학습하는 것이 가능합니다. 이렇게 하면 다른 사람이나 에이전트의 행동을 관찰하거나 이전의 정책으로 생성된 데이터를 재사용할 수 있습니다. 이것이 재사용이라는 개념입니다.